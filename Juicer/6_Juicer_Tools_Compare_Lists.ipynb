{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Compare Tool from Juicer for Identifying Unique Loops Between Samples\n",
    "this looks at loops in two sample bedpes and marks them as one of the following:  \n",
    "- A\\*/B\\* - unique loops in first/second file that overlap with no loops in second/first file  \n",
    "- A/B - loops in first/second file that overlap with loops in second/first file, but are not identical to any loops in second/first file.\n",
    "    - depends on the threshold radius option value (-m). If the threshold option is set to 0 then none of these will be assigned and the tools will only look for exact matching loops (A\\*/B\\*). \n",
    "- Common - loops identical to both first and second file  \n",
    "\n",
    "### NOTE\n",
    "this may give unexpected results when the -m option is set to a larger range. For example, if run to compare a file against itself it may assign some loops as unique (all loops should be common if comparing a file against itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the value that will go into the -m option in the compare list juicer tool. Is the radius (in bp) to check for overlap. In other words a value above zero will allow for unidentical loops to be counted as overlapping if they are close enough. (ex: 25000)\n",
    "THRESHOLD=25000#None\n",
    "\n",
    "#name to add to files generated depending on the threshold value\n",
    "if(THRESHOLD is None):\n",
    "    fname_threshold = \"default\"\n",
    "else:\n",
    "    fname_threshold = THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory containing all the sample folders. each sample folder should be named after the sample\n",
    "JUICER_DIR=\"/path/to/juicer\"\n",
    "#the rest of these are created in the next cell\n",
    "ANALYSIS_DIR = JUICER_DIR+\"/overlap_analysis\"\n",
    "SAMPLES_DIR = JUICER_DIR+\"/overlap_analysis/samples\"\n",
    "SAMPLES_NH_DIR = JUICER_DIR+\"/overlap_analysis/samples_no_header\"\n",
    "SCRIPT_DIR = JUICER_DIR+\"/overlap_analysis/scripts\"\n",
    "OVERLAP_DIR= JUICER_DIR+\"/overlap_analysis/overlap\"\n",
    "SHUFFLE_DIR = JUICER_DIR+\"/overlap_analysis/shuffle\"\n",
    "MISC_DIR = JUICER_DIR+\"/overlap_analysis/misc\"\n",
    "COMPARE_DIR=JUICER_DIR+\"/overlap_analysis/compare_lists\"\n",
    "RESULTS_DIR = JUICER_DIR+\"/overlap_analysis/results\"\n",
    "OUT_DIR = f\"{RESULTS_DIR}/compare_lists_{fname_threshold}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {COMPARE_DIR}\n",
    "!mkdir {RESULTS_DIR}\n",
    "!mkdir {OUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of the sample names taken from the juicer directory\n",
    "SAMPLES = sorted([ name for name in os.listdir(JUICER_DIR) if os.path.isdir(os.path.join(JUICER_DIR, name)) and 'HICS' in name ])\n",
    "print(len(SAMPLES))\n",
    "print(SAMPLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCRIPT_DIR+\"/compare_lists.swarm\",\"w\") as swarm_file:\n",
    "    for i in range(0,len(SAMPLES)):\n",
    "    \n",
    "        for j in range(i,len(SAMPLES)):\n",
    "            sample1=SAMPLES[i]\n",
    "            sample2=SAMPLES[j]\n",
    "            \n",
    "            #if we didn't assign a value to the threshold radius then use whatever the default is. otherwise use it\n",
    "            if(THRESHOLD is None):\n",
    "                swarm_file.write(f\"/path/to/juicer_tools compare 0 hg38 {SAMPLES_DIR}/{sample1}.bedpe {SAMPLES_DIR}/{sample2}.bedpe {COMPARE_DIR}/{sample1}_{sample2}_{fname_threshold}_compare_loop_list.bedpe \\n\")\n",
    "            else:\n",
    "                swarm_file.write(f\"/path/to/juicer_tools compare 0 hg38 -m {THRESHOLD} {SAMPLES_DIR}/{sample1}.bedpe {SAMPLES_DIR}/{sample2}.bedpe {COMPARE_DIR}/{sample1}_{sample2}_{fname_threshold}_compare_loop_list.bedpe \\n\")\n",
    "            #print(str(i)+\" \" + str(j))\n",
    "    swarm_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"swarm -f {SCRIPT_DIR}/compare_lists.swarm -g 50 -t 10 --module=juicer --sbatch '--mail-type=ALL' --time=24:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "common_c={}\n",
    "common_p={}\n",
    "unique_c={}\n",
    "unique_p={}\n",
    "similar_c={}\n",
    "similar_p={}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(SAMPLES)):\n",
    "    row = {}\n",
    "    for j in range(0,len(SAMPLES)):\n",
    "        row[SAMPLES[j]]=None\n",
    "    common_c[SAMPLES[i]]=row.copy()\n",
    "    common_p[SAMPLES[i]]=row.copy()\n",
    "    unique_c[SAMPLES[i]]=row.copy()\n",
    "    unique_p[SAMPLES[i]]=row.copy()\n",
    "    similar_c[SAMPLES[i]]=row.copy()\n",
    "    similar_p[SAMPLES[i]]=row.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(0,len(SAMPLES)):\n",
    "    for j in range(i,len(SAMPLES)):\n",
    "        sample1=SAMPLES[i]\n",
    "        sample2=SAMPLES[j]\n",
    "        \n",
    "        sample1_loop_count = len(pd.read_csv(f\"{SAMPLES_DIR}/{sample1}.bedpe\",sep='\\t').index)\n",
    "        sample2_loop_count = len(pd.read_csv(f\"{SAMPLES_DIR}/{sample2}.bedpe\",sep='\\t').index)\n",
    "\n",
    "        file = pd.read_csv(f\"{COMPARE_DIR}/{sample1}_{sample2}_{fname_threshold}_compare_loop_list.bedpe\",sep='\\t')\n",
    "        #unique loops to sample1\n",
    "        As=len(file[file['parent_list']=='A*'].drop_duplicates().index)\n",
    "        #similar loops to sample1\n",
    "        A=len(file[file['parent_list']=='A'].drop_duplicates().index)\n",
    "        #unique loops to sample2\n",
    "        Bs=len(file[file['parent_list']=='B*'].drop_duplicates().index)\n",
    "        #similar loops to sample2\n",
    "        B=len(file[file['parent_list']=='B'].drop_duplicates().index)\n",
    "        #common loops to both samples\n",
    "        Common=len(file[file['parent_list']=='Common'].drop_duplicates().index)\n",
    "        \n",
    "        unique_c[sample1][sample2]=As\n",
    "        unique_c[sample2][sample1]=Bs\n",
    "        \n",
    "        unique_p[sample1][sample2]=As/sample1_loop_count * 100\n",
    "        unique_p[sample2][sample1]=Bs/sample2_loop_count * 100\n",
    "        \n",
    "        similar_c[sample1][sample2]=A\n",
    "        similar_c[sample2][sample1]=B\n",
    "        \n",
    "        similar_p[sample1][sample2]=A/sample1_loop_count * 100\n",
    "        similar_p[sample2][sample1]=B/sample2_loop_count * 100\n",
    "        \n",
    "        common_c[sample1][sample2]=Common\n",
    "        common_c[sample2][sample1]=Common\n",
    "        \n",
    "        common_p[sample1][sample2]=Common/sample1_loop_count * 100\n",
    "        common_p[sample2][sample1]=Common/sample2_loop_count * 100\n",
    "        \n",
    "\n",
    "uc = pd.DataFrame(data = unique_c)\n",
    "uc.to_csv(f\"{OUT_DIR}/compare_loop_list_{fname_threshold}_unique_counts.csv\")\n",
    "up = pd.DataFrame(data = unique_p)\n",
    "up.to_csv(f\"{OUT_DIR}/compare_loop_list_{fname_threshold}_unique_percents.csv\")\n",
    "\n",
    "sc = pd.DataFrame(data = similar_c)\n",
    "sc.to_csv(f\"{OUT_DIR}/compare_loop_list_{fname_threshold}_similar_counts.csv\")\n",
    "sp = pd.DataFrame(data = similar_p)\n",
    "sp.to_csv(f\"{OUT_DIR}/compare_loop_list_{fname_threshold}_similar_percents.csv\")\n",
    "        \n",
    "        \n",
    "cc = pd.DataFrame(data = common_c)\n",
    "cc.to_csv(f\"{OUT_DIR}/compare_loop_list_{fname_threshold}_common_counts.csv\")\n",
    "cp = pd.DataFrame(data = common_p)\n",
    "cp.to_csv(f\"{OUT_DIR}/compare_loop_list_{fname_threshold}_common_percents.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the compare result file\n",
    "comp=pd.read_csv(f\"{COMPARE_DIR}/HICS_CS25i_FBn_d25_S6_HICS_CS25i_d0_S9_{fname_threshold}_compare_loop_list.bedpe\", sep='\\t')\n",
    "print(comp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = pd.read_csv(f\"{SAMPLES_DIR}/HICS_CS25i_FBn_d25_S6.bedpe\")\n",
    "print(sample1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = pd.read_csv(f\"{SAMPLES_DIR}/HICS_CS25i_d0_S9.bedpe\")\n",
    "print(sample2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how many were listed as common between sample1 and sample2\n",
    "compC= comp[comp['parent_list']=='Common']\n",
    "print(compC.shape)\n",
    "print(compC.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how many sample1 loops were within the threshold radius for overlap with sample2 loops but were not identical between the two samples\n",
    "compA= comp[comp['parent_list']=='A']\n",
    "print(compA.shape)\n",
    "print(compA.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how many loops were completely unique to sample1\n",
    "compAs= comp[comp['parent_list']=='A*']\n",
    "print(compAs.shape)\n",
    "print(compAs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how many sample2 loops were within the threshold radius for overlap with sample1 loops but were not identical between the two samples\n",
    "compB= comp[comp['parent_list']=='B']\n",
    "print(compB.shape)\n",
    "print(compB.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how many loops were completely unique to sample2\n",
    "compBs= comp[comp['parent_list']=='B*']\n",
    "print(compBs.shape)\n",
    "print(compBs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge between the subset dataframes to check they are unique or belong to the right sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.merge(compA,compAs, on=['chr1','x1','x2','chr2','y1','y2'],how = 'inner')\n",
    "print(compA.shape)\n",
    "print(compAs.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.merge(compA,compB, on=['chr1','x1','x2','chr2','y1','y2'],how = 'inner')\n",
    "print(compA.shape)\n",
    "print(compB.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.merge(compA,compC, on=['chr1','x1','x2','chr2','y1','y2'],how = 'inner')\n",
    "print(compA.shape)\n",
    "print(compC.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare bedtools overlap implementation vs juicer compare list tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_s1_s2_overlap = pd.read_csv(f\"{OVERLAP_DIR}/HICS_CS25i_FBn_d25_S6_HICS_CS25i_d0_S9_overlap.txt\", sep='\\t',header=None)\n",
    "\n",
    "print(bed_s1_s2_overlap.shape)\n",
    "print(bed_s1_s2_overlap.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_s1 = bed_s1_s2_overlap.iloc[:,0:6]\n",
    "bed_s1.columns = ['chr1','x1','x2','chr2','y1','y2']\n",
    "bed_s1['chr1']=bed_s1['chr1'].str.replace('chr','')\n",
    "bed_s1['chr2']=bed_s1['chr2'].str.replace('chr','')\n",
    "bed_s1 = bed_s1.drop_duplicates()\n",
    "print(bed_s1.shape)\n",
    "print(bed_s1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_s2_s1_overlap = pd.read_csv(f\"{OVERLAP_DIR}/HICS_CS25i_d0_S9_HICS_CS25i_FBn_d25_S6_overlap.txt\", sep='\\t',header=None)\n",
    "\n",
    "print(bed_s2_s1_overlap.shape)\n",
    "print(bed_s2_s1_overlap.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_s2 = bed_s2_s1_overlap.iloc[:,0:6]\n",
    "bed_s2.columns = ['chr1','x1','x2','chr2','y1','y2']\n",
    "bed_s2['chr1']=bed_s2['chr1'].str.replace('chr','')\n",
    "bed_s2['chr2']=bed_s2['chr2'].str.replace('chr','')\n",
    "bed_s2 = bed_s2.drop_duplicates()\n",
    "print(bed_s2.shape)\n",
    "print(bed_s2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many are identical/commone between the two\n",
    "\n",
    "mer = pd.merge(bed_s1, bed_s2, on=['chr1','x1','x2','chr2','y1','y2'], how = 'inner')\n",
    "print(mer.shape)\n",
    "print(mer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge compare list sample2/B uniques with bedtools overlap for sample2\n",
    "print(compBs.shape)\n",
    "print(bed_s2.shape)\n",
    "\n",
    "mer = pd.merge(compBs, bed_s2, on=['chr1','x1','x2','chr2','y1','y2'], how = 'inner')\n",
    "print(mer.shape)\n",
    "print(mer.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ so different ones count as unique between the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge compare list commons with bedtools overlap for sample2\n",
    "print(compC.shape)\n",
    "print(bed_s2.shape)\n",
    "\n",
    "mer = pd.merge(compC, bed_s2, on=['chr1','x1','x2','chr2','y1','y2'], how = 'inner')\n",
    "print(mer.shape)\n",
    "print(mer.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ so same ones count as identical between the two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge compare list sample2/B similars with bedtools overlap for sample2\n",
    "print(compB.shape)\n",
    "print(bed_s2.shape)\n",
    "\n",
    "mer = pd.merge(compB, bed_s2, on=['chr1','x1','x2','chr2','y1','y2'], how = 'inner')\n",
    "print(mer.shape)\n",
    "print(mer.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ so different ones count as similar between the two methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
