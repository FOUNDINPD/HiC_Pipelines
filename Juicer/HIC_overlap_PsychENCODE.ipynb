{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiC Loop Overlap with PsychENCODE HiC Data\n",
    "- **Author** - Frank Grenn\n",
    "- **Date Started** - March 2020\n",
    "- **Quick Description:** code to process the psychencode loop data to compare with our hic data. involves mapping their hg19 positions to hg38 and using bedtools to compare overlapping regions.\n",
    "- **Data:**  \n",
    "[PsychENCODE Data](http://resource.psychencode.org/)  \n",
    "[PsychENCODE Paper](https://science.sciencemag.org/content/362/6420/eaat8464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP = '/path/to/juicer/overlap_analysis/misc'\n",
    "PE = TEMP+'/psychencode'\n",
    "SCRIPT = '/path/to/juicer/overlap_analysis/scripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {TEMP}\n",
    "!mkdir {PE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Liftover PsychENCODE Data from hg19 to hg38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) download the data, the liftover chain file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HiC Contact Matrices (Probably don't need but good to check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o {PE}/PIP-01_DLPFC.10kb.txt.tar.gz http://resource.psychencode.org/Datasets/Pipeline/HiC_matrices/PIP-01_DLPFC.10kb.txt.tar.gz\n",
    "!curl -o {PE}/PIP-02_DLPFC.40kb.txt.tar.gz http://resource.psychencode.org/Datasets/Pipeline/HiC_matrices/PIP-02_DLPFC.40kb.txt.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf {PE}/PIP-01_DLPFC.10kb.txt.tar.gz --verbose -C {PE}\n",
    "!tar -xvf {PE}/PIP-02_DLPFC.40kb.txt.tar.gz --verbose -C {PE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Loop Interaction Regions file \n",
    "will need to convert to bedpe format later  \n",
    "also will need to convert from hg19 to hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o {PE}/Promoter-anchored_chromatin_loops.bed http://resource.psychencode.org/Datasets/Integrative/Promoter-anchored_chromatin_loops.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Promoter Enhancer Region Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o {PE}/INT-16_HiC_EP_linkages.csv http://resource.psychencode.org/Datasets/Integrative/INT-16_HiC_EP_linkages.csv\n",
    "!curl -o {PE}/INT-16_HiC_EP_linkages_cross_assembly.csv http://resource.psychencode.org/Datasets/Integrative/INT-16_HiC_EP_linkages_cross_assembly.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Liftover chain file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o {TEMP}/hg19ToHg38.over.chain.gz https://hgdownload.soe.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) format the PsychENCODE loop file to a bedpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expand the bed to a bedpe with ids for the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {PE}/Promoter-anchored_chromatin_loops.bed | tail -n +2 | awk -v RS='\\r?\\n' 'BEGIN{OFS=\"\\t\"} {print $1,$2,$3,$1,$4,$5,\"loop_\"NR,\".\",\"+\",\"-\"}' > {PE}/Promoter-anchored_chromatin_loops.bedpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head {PE}/Promoter-anchored_chromatin_loops.bedpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) now split into two separate bed files to liftover separately and merge together later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedpe = pd.read_csv(f\"{PE}/Promoter-anchored_chromatin_loops.bedpe\", sep=\"\\t\", header=None)\n",
    "bedpe.columns = [\"chr1\", \"x1\", \"x2\", \"chr2\", \"y1\", \"y2\", \"loop_id\", \"score\", \"strand1\", \"strand2\"]\n",
    "print(bedpe.shape)\n",
    "print(bedpe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed1 = bedpe[['chr1','x1','x2','loop_id']]\n",
    "bed1.columns = ['chrom','chromStart','chromEnd','name']\n",
    "bed1['chrom'] = 'chr'+bed1['chrom'].astype(str)\n",
    "print(bed1.shape)\n",
    "print(bed1.tail())\n",
    "bed1.to_csv(f\"{PE}/PE1.bed\",sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed2 = bedpe[['chr2','y1','y2','loop_id']]\n",
    "bed2.columns = ['chrom','chromStart','chromEnd','name']\n",
    "bed2['chrom'] = 'chr'+bed2['chrom'].astype(str)\n",
    "print(bed2.shape)\n",
    "print(bed2.tail())\n",
    "bed2.to_csv(f\"{PE}/PE2.bed\",sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Compare the original `Promoter-anchored_chromatin_loops.bed` to the `INT-16_HiC_EP_linkages_cross_assembly.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed = pd.read_csv(f\"{PE}/Promoter-anchored_chromatin_loops.bed\",sep = \"\\t\")\n",
    "bed.columns = [\"chr\", \"x1\", \"x2\", \"y1\", \"y2\"]\n",
    "bed['chr'] = 'chr'+bed['chr'].astype(str)\n",
    "print(\"cols:\")\n",
    "print(bed.columns)\n",
    "print(bed.shape)\n",
    "print(bed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP = pd.read_csv(f\"{PE}/INT-16_HiC_EP_linkages_cross_assembly.csv\")\n",
    "print(EP.shape)\n",
    "print(EP.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now merge on the hg19 col to see if there is anything in common with the original `Promoter-anchored_chromatin_loops.bed` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19_merge = pd.merge(left=bed, right = EP, left_on = [\"chr\", \"x1\"], right_on = [\"Enhancer_Chromosome_hg19\",\"Transcription_Start_Site_hg19\"], how  = \"inner\")\n",
    "print(hg19_merge.shape)\n",
    "print(hg19_merge.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Liftover the two bed files from hg19 to hg38 using i) the UCSC Liftover tool or ii) the CrossMap tool\n",
    "probably use UCSC liftover since CrossMap seems to give duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) UCSC Liftover\n",
    "here: https://genome.ucsc.edu/cgi-bin/hgLiftOver  \n",
    "submit the `PE1.bed` and `PE2.bed`\n",
    "* need to paste in the chr, x1, x2 (optional name col) columns without headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Use CrossMap to do the conversion\n",
    "available on biowulf  \n",
    "also required the chain file downloaded previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"module load crossmap\")\n",
    "print(f\"crossmap bed {TEMP}/hg19ToHg38.over.chain.gz {PE}/PE1.bed > {PE}/PE1_crossmap_lift.bed\")\n",
    "print(f\"crossmap bed {TEMP}/hg19ToHg38.over.chain.gz {PE}/PE2.bed > {PE}/PE2_crossmap_lift.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PE1L = pd.read_csv(f\"{PE}/PE1_crossmap_lift.bed\", sep=\"\\t\",header=None)\n",
    "PE1L.columns = [\"chr_o\",\"x1_o\",\"x2_o\",\"loop_o\", \"arrow\", \"chr_l\", \"x1_l\", \"x2_l\", \"loop_l\"]\n",
    "print(bed1.shape)\n",
    "print(PE1L.shape)\n",
    "print(PE1L.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PE2L = pd.read_csv(f\"{PE}/PE1_crossmap_lift.bed\", sep=\"\\t\",header=None)\n",
    "PE2L.columns = [\"chr_o\",\"x1_o\",\"x2_o\",\"loop_o\", \"arrow\", \"chr_l\", \"x1_l\", \"x2_l\", \"loop_l\"]\n",
    "print(bed2.shape)\n",
    "print(PE2L.shape)\n",
    "print(PE2L.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Merge the two bed files from the liftover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PE1_UCSC = pd.read_csv(f\"{PE}/PE1_ucsc_liftover_hg38.bed\", sep=\"\\t\", header = None)\n",
    "PE1_UCSC.columns = [\"chr1\", \"x1\", \"x2\", \"loop_id\"]\n",
    "print(PE1_UCSC.shape)\n",
    "print(PE1_UCSC.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PE2_UCSC = pd.read_csv(f\"{PE}/PE2_ucsc_liftover_hg38.bed\", sep=\"\\t\", header = None)\n",
    "PE2_UCSC.columns = [\"chr2\", \"y1\", \"y2\", \"loop_id\"]\n",
    "print(PE2_UCSC.shape)\n",
    "print(PE2_UCSC.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now inner join by loop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_bedpe = pd.merge(left = PE1_UCSC, right = PE2_UCSC, on = \"loop_id\", how = \"inner\")\n",
    "lift_bedpe = lift_bedpe[['chr1','x1','x2','chr2','y1','y2','loop_id']]\n",
    "print(lift_bedpe.shape)\n",
    "print(lift_bedpe.head())\n",
    "lift_bedpe.to_csv(f\"{PE}/Promoter-anchored_chromatin_loops_hg38.bedpe\",sep=\"\\t\",index=None)\n",
    "lift_nh = lift_bedpe[['chr1','x1','x2','chr2','y1','y2']]\n",
    "lift_nh.to_csv(f\"{PE}/Promoter-anchored_chromatin_loops_hg38_nh.bedpe\",sep=\"\\t\",index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Check for overlap between our bedpes and PsychENCODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constants for directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory containing all the sample folders. each sample folder should be named after the sample\n",
    "JUICER_DIR=\"/path/to/juicer\"\n",
    "\n",
    "ANALYSIS_DIR = JUICER_DIR+\"/overlap_analysis\"\n",
    "SAMPLES_DIR = JUICER_DIR+\"/overlap_analysis/samples\"\n",
    "SAMPLES_NH_DIR = JUICER_DIR+\"/overlap_analysis/samples_no_header\"\n",
    "SCRIPT_DIR = JUICER_DIR+\"/overlap_analysis/scripts\"\n",
    "OVERLAP_DIR= JUICER_DIR+\"/overlap_analysis/overlap\"\n",
    "SHUFFLE_DIR = JUICER_DIR+\"/overlap_analysis/shuffle\"\n",
    "MISC_DIR = JUICER_DIR+\"/overlap_analysis/misc\"\n",
    "RESULTS_DIR = JUICER_DIR+\"/overlap_analysis/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the functions: ` %load path/to/overlapBedpeAndBed.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load new/overlapBedpeAndBed.py\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#swarm sample Bedpe and Single Bedpe Overlap\n",
    "def generate_bedpe_bedpe_overlap_swarm(sample_list, sample_nh_dir, bedpe, otype, overlap_dir, script_dir):\n",
    "\n",
    "    bedpe_name = os.path.splitext(os.path.basename(bedpe))[0]\n",
    "\n",
    "    with open(f\"{script_dir}/all_{bedpe_name}_overlap.swarm\",'w') as file_handler:\n",
    "        for sample in sample_list:\n",
    "            file_handler.write(f\"bedtools pairtopair -a {sample_nh_dir}/{sample}.bedpe -b {bedpe} -type {otype} > \\\n",
    "{overlap_dir}/{sample}_{bedpe_name}_overlap.txt\\n\")\n",
    "\n",
    "    file_handler.close()\n",
    "    os.system(f\"swarm -f {script_dir}/all_{bedpe_name}_overlap.swarm --module bedtools --g 50\")\n",
    "    \n",
    "#single Bedpe and Bed Overlap\n",
    "def run_bedpe_bed_overlap(sample, sample_nh_dir, bed, otype, overlap_dir):\n",
    "    bed_name = os.path.splitext(os.path.basename(bed))[0]\n",
    "    os.system(f\"module load bedtools; \\\n",
    "              bedtools pairtobed -a {sample_nh_dir}/{sample}.bedpe -b {bed} -type {otype} > {overlap_dir}/{sample}_{bed_name}_overlap.txt\")\n",
    "    \n",
    "#copy the loop files and rename\n",
    "def get_sample_loop_files(juicer_dir, sample_dir, sample_list):\n",
    "    for sample in sample_list:\n",
    "        os.system(f\"cp {juicer_dir}/{sample}/aligned/inter_30_loops/merged_loops.bedpe {sample_dir}\")\n",
    "        os.system(f\"mv {sample_dir}/merged_loops.bedpe {sample_dir}/{sample}.bedpe\")\n",
    "\n",
    "#reformat the loop files and relocate them\n",
    "def get_no_header_loop_files(sample_dir, sample_nh_dir, sample_list):\n",
    "    for sample in sample_list:\n",
    "        #read the bedpe and prepend 'chr' to the two chromosome cols\n",
    "        sample_bedpe = pd.read_csv(f\"{sample_dir}/{sample}.bedpe\",sep='\\t')\n",
    "        sample_bedpe['chr1'] = 'chr' + sample_bedpe['chr1'].astype(str)\n",
    "        sample_bedpe['chr2'] = 'chr' + sample_bedpe['chr2'].astype(str)\n",
    "        sample_bedpe=sample_bedpe[['chr1','x1','x2','chr2','y1','y2']]\n",
    "\n",
    "        sample_bedpe.to_csv(f\"{sample_nh_dir}/{sample}.bedpe\", sep='\\t', header=False, index=None, mode='w+')\n",
    "\n",
    "#get a df of overlap data between a bedpe and bed \n",
    "def get_bedpe_bed_overlap_data(overlap_file, sample_file):\n",
    "    \n",
    "    sample_name = os.path.splitext(os.path.basename(sample_file))[0]\n",
    "    sample_lines = len(pd.read_csv(sample_file,sep=\"\\t\",header=None).index)\n",
    "    #read the overlap output\n",
    "    #overlap_data = pd.read_csv(f\"{overlap_dir}/{sample}_{bed_name}_overlap.txt\",sep=\"\\t\",header=None)\n",
    "    if(os.path.getsize(overlap_file) == 0):\n",
    "    \treturn pd.DataFrame(data={'sample':[sample_name], 'counts':0, 'total':[sample_lines], 'percent':[0]})\n",
    "    overlap_data = pd.read_csv(overlap_file, sep = \"\\t\", header = None)\n",
    "    \n",
    "    #we only want the first 6 cols corresponding to the bedpe loops for now\n",
    "    overlap_subset = overlap_data.iloc[:,:6]\n",
    "    #remove duplicate rows\n",
    "    unique_overlaps = overlap_subset.drop_duplicates()\n",
    "    #count the number of overlaps\n",
    "    overlap_counts = len(unique_overlaps.index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ret_df = pd.DataFrame(data={'sample':[sample_name], 'counts':[overlap_counts], 'total':[sample_lines], 'percent':[(overlap_counts/sample_lines * 100)]})\n",
    "    \n",
    "    return ret_df\n",
    "\n",
    "#All sample bedpe overlap with one bed file\n",
    "def generate_bedpe_bed_overlap_swarm(sample_list, sample_nh_dir , bed, otype, overlap_dir, script_dir):\n",
    "\n",
    "    bed_name = os.path.splitext(os.path.basename(bed))[0]\n",
    "\n",
    "    with open(f\"{script_dir}/all_{bed_name}_overlap.swarm\",'w') as file_handler:\n",
    "        for sample in sample_list:\n",
    "            file_handler.write(f\"bedtools pairtobed -a {sample_nh_dir}/{sample}.bedpe -b {bed} -type {otype} > \\\n",
    "{overlap_dir}/{sample}_{bed_name}_overlap.txt\\n\")\n",
    "\n",
    "    file_handler.close()\n",
    "    !swarm -f {script_dir}/all_{bed_name}_overlap.swarm --module bedtools --g 50\n",
    "    \n",
    "    \n",
    "    \n",
    "#get a df of overlap data between a bedpe and bedpe\n",
    "def get_bedpe_bedpe_overlap_data(overlap_file, sample_file):\n",
    "    \n",
    "    sample_name = os.path.splitext(os.path.basename(sample_file))[0]\n",
    "    sample_lines = len(pd.read_csv(sample_file,sep=\"\\t\",header=None).index)\n",
    "    #read the overlap output\n",
    "    #overlap_data = pd.read_csv(f\"{overlap_dir}/{sample}_{bed_name}_overlap.txt\",sep=\"\\t\",header=None)\n",
    "    if(os.path.getsize(overlap_file) == 0):\n",
    "    \treturn pd.DataFrame(data={'sample':[sample_name], 'counts':0, 'total':[sample_lines], 'percent':[0]})\n",
    "    overlap_data = pd.read_csv(overlap_file, sep = \"\\t\", header = None)\n",
    "    \n",
    "    #we only want the first 6 cols corresponding to the bedpe loops for now\n",
    "    overlap_subset = overlap_data.iloc[:,:6]\n",
    "    #remove duplicate rows\n",
    "    unique_overlaps = overlap_subset.drop_duplicates()\n",
    "    #count the number of overlaps\n",
    "    overlap_counts = len(unique_overlaps.index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ret_df = pd.DataFrame(data={'sample':[sample_name], 'counts':[overlap_counts], 'total':[sample_lines], 'percent':[(overlap_counts/sample_lines * 100)]})\n",
    "    \n",
    "    return ret_df\n",
    "\n",
    "#get a df for all sample bedpe overlap with another bedpe\n",
    "def get_bedpe_list_bedpe_overlap_data(sample_list, sample_nh_dir , bedpe, overlap_dir, delete = False):\n",
    "\n",
    "    overlap_df = pd.DataFrame()\n",
    "    bedpe_name = os.path.splitext(os.path.basename(bedpe))[0]\n",
    "    for sample in sample_list:\n",
    "        overlap_file = overlap_dir + '/'+sample+'_'+bedpe_name+'_overlap.txt'\n",
    "        sample_file = sample_nh_dir + '/' + sample + '.bedpe'\n",
    "        sample_overlap = get_bedpe_bedpe_overlap_data(overlap_file = overlap_file, sample_file = sample_file)\n",
    "        overlap_df = overlap_df.append(sample_overlap, ignore_index = True)\n",
    "        print(sample)\n",
    "        if(delete):\n",
    "            os.remove(overlap_file)\n",
    "    return overlap_df\n",
    "\n",
    "#get a df for all sample bedpe overlap with a bed file\n",
    "def get_bedpe_list_bed_overlap_data(sample_list, sample_nh_dir , bed, overlap_dir, delete = False):\n",
    "\n",
    "    overlap_df = pd.DataFrame()\n",
    "    bed_name = os.path.splitext(os.path.basename(bed))[0]\n",
    "    for sample in sample_list:\n",
    "        overlap_file = overlap_dir + '/'+sample+'_'+bed_name+'_overlap.txt'\n",
    "        sample_file = sample_nh_dir + '/' + sample + '.bedpe'\n",
    "        sample_overlap = get_bedpe_bed_overlap_data(overlap_file = overlap_file, sample_file = sample_file)\n",
    "        overlap_df = overlap_df.append(sample_overlap, ignore_index = True)\n",
    "        print(sample)\n",
    "        if(delete):\n",
    "            os.remove(overlap_file)\n",
    "    return overlap_df\n",
    "\n",
    "\n",
    "#overlap samples with each other\n",
    "def generate_bedpe_between_overlap_swarm(sample_list, sample_nh_dir, otype, overlap_dir, script_dir):\n",
    "\n",
    "    with open(f\"{script_dir}/all_samples_between_overlap.swarm\",'w') as file_handler:\n",
    "        for sample1 in sample_list:\n",
    "        \n",
    "            for sample2 in sample_list:\n",
    "                if(sample1 != sample2):\n",
    "                    file_handler.write(f\"bedtools pairtopair -a {sample_nh_dir}/{sample1}.bedpe -b {sample_nh_dir}/{sample2}.bedpe -type {otype} > \\\n",
    "{overlap_dir}/{sample1}_{sample2}_overlap.txt\\n\")\n",
    "            \n",
    "\n",
    "\n",
    "    file_handler.close()\n",
    "    os.system(f\"swarm -f {script_dir}/all_samples_between_overlap.swarm --module bedtools --g 50\")\n",
    "\n",
    "#get df/matrix of between sample overlap data\n",
    "def get_bedpe_between_overlap_data(sample_list, sample_nh_dir, overlap_dir, delete = False):\n",
    "\n",
    "    sample_list = sorted(sample_list)\n",
    "    all_percent_data={}\n",
    "    all_count_data={}\n",
    "    for sample in sample_list:\n",
    "        if(os.stat(f\"{sample_nh_dir}/{sample}.bedpe\").st_size != 0):\n",
    "            sample_lines = len(pd.read_csv(f\"{sample_nh_dir}/{sample}.bedpe\",sep=\"\\t\").index)\n",
    "        else:\n",
    "            sample_lines=0\n",
    "\n",
    "        comp_percent_data={}\n",
    "        comp_count_data={}\n",
    "\n",
    "        for comp_sample in sample_list:\n",
    "            if sample!=comp_sample:\n",
    "                if(os.stat(f\"{overlap_dir}/{sample}_{comp_sample}_overlap.txt\").st_size !=0 ):\n",
    "                    \n",
    "                    sample_file = f\"{sample_nh_dir}/{sample}.bedpe\"\n",
    "                    overlap_file = f\"{overlap_dir}/{sample}_{comp_sample}_overlap.txt\"\n",
    "                    df = get_bedpe_bedpe_overlap_data(overlap_file,sample_file)\n",
    "                    comp_count_data[comp_sample] = df.iloc[0]['counts']\n",
    "                    comp_percent_data[comp_sample] = df.iloc[0]['percent']\n",
    "                    \n",
    "\n",
    "\n",
    "            if sample==comp_sample:\n",
    "                comp_percent_data[comp_sample]=None\n",
    "                comp_count_data[comp_sample]=None\n",
    "        all_percent_data[sample]=comp_percent_data\n",
    "        all_count_data[sample]=comp_count_data\n",
    "\n",
    "    percent_df = pd.DataFrame(data=all_percent_data)\n",
    "    count_df = pd.DataFrame(data=all_count_data)\n",
    "    return count_df, percent_df\n",
    "\n",
    "#shuffle a bedpe file n times\n",
    "def shuffle_bedpe(sample, n, sample_nh_dir, shuffle_dir, sizes):\n",
    "\n",
    "    #just shuffle once\n",
    "    if(n==1):\n",
    "        !(module load bedtools; \\\n",
    "     bedtools shuffle -i {sample_nh_dir}/{sample}.bedpe -g {sizes} -bedpe > {shuffle_dir}/{sample}_shuffle.bedpe)\n",
    "    else:\n",
    "        for i in range(n):\n",
    "            !(module load bedtools; \\\n",
    "     bedtools shuffle -i {sample_nh_dir}/{sample}.bedpe -g {sizes} -bedpe > {shuffle_dir}/{sample}_shuffle_{i}.bedpe)\n",
    "\n",
    "#shuffle all the sample bedpes n times\n",
    "def shuffle_bedpe_list(sample_list, n, sample_nh_dir, shuffle_dir, sizes):\n",
    "\n",
    "    for sample in sample_list:\n",
    "        shuffle_bedpe(sample = sample, n = n, sample_nh_dir = sample_nh_dir, shuffle_dir = shuffle_dir, sizes = sizes)\n",
    "\n",
    "#check for overlap with a bed file in all shuffled sample bedpes\n",
    "def shuffle_swarm_overlap(sample_list, n, sample_nh_dir , bed, otype, shuffle_dir, overlap_dir, script_dir):\n",
    "\n",
    "    bed_name = os.path.splitext(os.path.basename(bed))[0]\n",
    "    \n",
    "\n",
    "    with open(f\"{script_dir}/all_{bed_name}_shuffle_overlap.swarm\",'w') as file_handler:\n",
    "        if(n==1):\n",
    "            for sample in sample_list:\n",
    "                file_handler.write(f\"bedtools pairtobed -a {shuffle_dir}/{sample}_shuffle.bedpe -b {bed} -type {otype} > \\\n",
    "{overlap_dir}/{sample}_shuffle_{bed_name}_overlap.txt\\n\")\n",
    "        if(n>1):\n",
    "            for sample in sample_list:\n",
    "                for i in range(n):\n",
    "                    file_handler.write(f\"bedtools pairtobed -a {shuffle_dir}/{sample}_shuffle_{i}.bedpe -b {bed} -type {otype} > \\\n",
    "{overlap_dir}/{sample}_shuffle_{i}_{bed_name}_overlap.txt\\n\")\n",
    "    file_handler.close()\n",
    "    !swarm -f {script_dir}/all_{bed_name}_shuffle_overlap.swarm --module bedtools --g 50\n",
    "    \n",
    "#get overlap data for all shuffled bedpe files\n",
    "def get_bedpe_list_bed_shuffle_overlap_data(sample_list, shuffle_dir, n, bed, overlap_dir, delete = False):\n",
    "    overlap_df = pd.DataFrame()\n",
    "    bed_name = os.path.splitext(os.path.basename(bed))[0]\n",
    " \n",
    "    if(n==1):\n",
    "        for sample in sample_list:\n",
    "            overlap_file = overlap_dir + '/'+sample+'_shuffle_'+bed_name+'_overlap.txt'\n",
    "            sample_file = shuffle_dir + '/' + sample + '_shuffle.bedpe'\n",
    "            sample_overlap = get_bedpe_bed_overlap_data(overlap_file = overlap_file, sample_file = sample_file)\n",
    "            overlap_df = overlap_df.append(sample_overlap, ignore_index = True)\n",
    "            print(sample)\n",
    "            if(delete):\n",
    "                os.remove(overlap_file)\n",
    "                os.remove(sample_file)\n",
    "    elif (n>1):\n",
    "        for sample in sample_list:\n",
    "            for i in range(n):\n",
    "                overlap_file = overlap_dir + '/'+sample+'_shuffle_' + str(i) +'_'+bed_name+'_overlap.txt'\n",
    "                sample_file = shuffle_dir + '/' + sample + '_shuffle_' + str(i) + '.bedpe'\n",
    "                sample_overlap = get_bedpe_bed_overlap_data(overlap_file = overlap_file, sample_file = sample_file)\n",
    "                overlap_df = overlap_df.append(sample_overlap, ignore_index = True)\n",
    "                print(sample + ' ' + str(i))\n",
    "                if(delete):\n",
    "                    os.remove(overlap_file)\n",
    "                    os.remove(sample_file)\n",
    "    return overlap_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make directories and run the setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {ANALYSIS_DIR}\n",
    "!mkdir {SAMPLES_DIR}\n",
    "!mkdir {SAMPLES_NH_DIR}\n",
    "!mkdir {SCRIPT_DIR}\n",
    "!mkdir {OVERLAP_DIR}\n",
    "!mkdir {SHUFFLE_DIR}\n",
    "!mkdir {MISC_DIR}\n",
    "!mkdir {RESULTS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of the sample names taken from the juicer directory\n",
    "SAMPLES = [ name for name in os.listdir(JUICER_DIR) if os.path.isdir(os.path.join(JUICER_DIR, name)) and 'HICS' in name ]\n",
    "print(len(SAMPLES))\n",
    "print(SAMPLES)\n",
    "get_sample_loop_files(JUICER_DIR, SAMPLES_DIR, SAMPLES)\n",
    "get_no_header_loop_files(SAMPLES_DIR, SAMPLES_NH_DIR, SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the overlap function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE='both'\n",
    "BEDPE_FILE=f\"{PE}/Promoter-anchored_chromatin_loops_hg38_nh.bedpe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_bedpe_bedpe_overlap_swarm(sample_list= SAMPLES, sample_nh_dir=SAMPLES_NH_DIR, bedpe=BEDPE_FILE, otype=TYPE, overlap_dir= OVERLAP_DIR, script_dir=SCRIPT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect the overlap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_bedpe_list_bedpe_overlap_data(sample_list= SAMPLES, sample_nh_dir=SAMPLES_NH_DIR , bedpe=BEDPE_FILE, overlap_dir= OVERLAP_DIR, delete = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(f\"{RESULTS_DIR}/psychencode_loop_overlap.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all sample 1 loops\n",
    "sample1_loops = pd.read_csv(f\"{SAMPLES_DIR}/HICS_CS25i_d0_S9.bedpe\",sep='\\t')\n",
    "print(sample1_loops.shape)\n",
    "#print(sample1_loops.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all psychencode loops\n",
    "PE_loops = pd.read_csv(f\"{BEDPE_FILE}\",sep='\\t',header=None)\n",
    "print(PE_loops.shape)\n",
    "#print(PE_loops.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the sample1 overlap with PE and dedup to get unique loops that overlap\n",
    "sample1_pe_overlap = pd.read_csv(f\"{OVERLAP_DIR}/HICS_CS25i_d0_S9_Promoter-anchored_chromatin_loops_hg38_nh_overlap.txt\",sep='\\t',header=None)\n",
    "print(sample1_pe_overlap.shape)\n",
    "print(sample1_pe_overlap.head())\n",
    "\n",
    "print(\"deduplicated\")\n",
    "s1_pe_overlap_s1_loops = sample1_pe_overlap.iloc[:,0:6]\n",
    "s1_pe_overlap_s1_loops_dedup = s1_pe_overlap_s1_loops.drop_duplicates()\n",
    "print(s1_pe_overlap_s1_loops_dedup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the percent overlap for sample1\n",
    "print(len(s1_pe_overlap_s1_loops_dedup.index))\n",
    "print(len(sample1_loops.index))\n",
    "print(str(len(s1_pe_overlap_s1_loops_dedup.index)/len(sample1_loops.index)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
